# Tutorial: Using Hugging Face DeepSeekR1 Local LLM in Cursor

## Introduction

This tutorial will guide you through the process of setting up and using the Hugging Face DeepSeekR1 local LLM in Cursor, an Integrated Development Environment (IDE) with built-in AI capabilities. By following these steps, you can run your local LLMs from Ollama in Cursor without needing to access OpenAI servers.

## Prerequisites

- Download and install [Ollama](https://ollama.com/download)
- Download and install [Ngrok](https://download.ngrok.com/)
- Download and install [Cursor](https://cursor.com)
- Obtain an OpenAI API key from [OpenAI](https://platform.openai.com/api-keys)

## Ollama Setup

1. Download the Ollama application from [Ollama's website](https://ollama.com) and install it.
2. Go to Hugging face or ollama models and pick your desired model
3. In your Terminal application, run the following command to pull the default llama LLM:

   ```bash
   ollama pull llama3.2
   ```
4. If you want to use a model from hugging face, for example [deepseek-r1](https://huggingface.co/mradermacher/FuseO1-DeepSeekR1-Qwen2.5-Instruct-32B-Preview-i1-GGUF/blob/main/FuseO1-DeepSeekR1-Qwen2.5-Instruct-32B-Preview.i1-Q4_K_M.gguf), use ollama pull hf.co/{user_name}/{repo_name}

   ```bash
   ollama pull hf.co/mradermacher/FuseO1-DeepSeekR1-Qwen2.5-Instruct-32B-Preview-i1-GGUF:IQ1_M
   ```

## Ngrok Setup

1. Download and install Ngrok from [Ngrok's website](https://download.ngrok.com/).
2. Create a free Ngrok account to obtain a token.
3. In your Terminal application, run the following command to add your Ngrok token:

   ```bash
   ngrok config add-authtoken <token>
   ```
4. Start the Ngrok endpoint by running:

   ```bash
   ngrok http 11434 --host-header="localhost:11434"
   ```

## OpenAI API Setup

1. Go to [OpenAI's API key page](https://platform.openai.com/api-keys) and generate a new API key.
2. Copy the secret key to your clipboard.

## Cursor IDE Setup

1. Download and install Cursor from [Cursor's website](https://cursor.com).
2. Open Cursor and navigate to the Settings by clicking the gear icon in the top right corner.
3. Open the Models tab and scroll down to the OpenAI API Key section.
4. Enable the OpenAI API Key option and paste the secret key from your clipboard. Click Verify.
5. Copy the forwarding URL generated by Ngrok from your Terminal(make sure to include `/v1` at the end).
6. Paste the URL into the Override OpenAI Base URL field in Cursor and click Save.

   - Note: You will need to update this URL every time you restart Ngrok as it changes.

## Adding and Using the Model in Cursor

1. Add a new model in Cursor and name it exactly as the Ollama model you pulled (e.g., `llama3.2` or `hf.co/mradermacher/FuseO1-DeepSeekR1-Qwen2.5-Instruct-32B-Preview-i1-GGUF:IQ1_M`).
2. Toggle the AI Pane and type your AI prompt in the Chat prompt panel. The local LLM should start interacting with you.

## Model Selection

For coding-specific tasks, consider using specialized models.

### To sum up, Run these three commands and follow the steps above if you're stuck anywhere 

```bash
   ngrok config add-authtoken {token}
   ollama pull hf.co/mradermacher/FuseO1-DeepSeekR1-Qwen2.5-Instruct-32B-Preview-i1-GGUF:IQ1_M
   ngrok http 11434 --host-header="localhost:11434"
```